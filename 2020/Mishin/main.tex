\def\mcirc{\mathbin{\scalerel*{\circ}{j}}}
\def\msquare{\mathord{\scalerel*{\Box}{gX}}}


\title{Реализация и применение строковых алгоритмов к задаче поиска
повторов в документации программного обеспечения}

\titlerunning{Применение ``полулокальных алгоритмов поиска``}

\author{Мишин Никита Матвеевич}

\authorrunning{Мишин Никита Матвеевич}

\tocauthor{Мишин Никита Матвеевич}
\institute{St Petersburg State University\\
	\email{mishinnikitam@gmail.com}}

\maketitle


\begin{abstract}
Данная работа посвящена исследованию применимости алгоритмов полулокального поиска наибольшей общей подпоследовательности и выравнивания строк (далее, просто ``полулокальные алгоритмы поиска``) для задач поиска повторов и групп повторов в документации программного обеспечения.
В работе представлен ряд алгоритмов поиска неточных повторов по заданному образцу на основе полулокальных алгоритмов поиска, в частности, разработана асимптотически более эффективная версия алгоритма из статьи Д.\,В. Луцива  (Programming and Computer Software’19) .
\end{abstract}

\section*{Введение}

% Абзац о том, что много документации ,она важна для разработки и сопровождения продуктов 
На сегодняшний день существует множество программных продуктов, и их количество с каждым годом лишь увеличивается.
% Вообще
Размер проектов исчисляется в строках кода и затраченных человеко-часах на соответствующую разработку.
Программные продукты часто могут содержать миллионы строк кода, на написание которых затрачены миллионы человеко-часов.
%\footnote{Код ядра линукса содержит более 27 млн строк кода, а на разработку ушло несколько сотен тысяч человеко-лет, 
%\emph{https://www.linux.com/news/linux-in-2020-27-8-million-lines-of-%code-in-the-kernel-1-3-million-in-systemd/, дата обращения 26.05.2020}}
%.
Соответственно, разработка и сопровождение таких сложных систем немыслимы без документации, количество которой лишь увеличивается.
% аналогичным образом растет с каждым новым продуктом.

% Детализируем, ссылками и мыслью, что качество документации важно и актуально
Важность сопроводительной документации не подвергается сомнению~\cite{kipyegen2013importance,chomal2014significance}.
Более конкретно, её качество напрямую влияет на жизненный цикл разработки системы, её конечную стоимость, время разработки, сопровождение и эксплуатацию и пр~\cite{plosch2014value}. 
К критериям качества документации относятся точность, структурированность, последовательность изложения, понятность.
Иными словами, задачи поддержания качества документации (всех ее критериев) на высоком уровне, а так же её написания, сопровождения и улучшения являются актуальными при создании, сопровождении и эксплуатации программных систем.
% Таким образом, различные виды программной документации играют важную роль в жизненном цикле разработки систем.

% Немного о клонах и их влиянии, -> их надо искать
Как в программном коде, так и в документации могут появляться \emph{текстовые повторы (текстовые клоны)}.
Влияние  \emph{текстовых повторов} на документацию различно.
% До сих пор нет четкого ответа на вопрос о влиянии \emph{текстовых повторов} на документацию.
К положительным факторам наличия \emph{повторов} в документации можно отнести
унификацию представления информации и создание общего контекста, что позволяет улучшить читаемость документации, её структурированность и передачу знаний (\emph{knowledge transfer}).
Несмотря на это, наличие клонов в документации влечет, как и в программном коде,  распространение ошибок и опечаток.
Также при наличии группы повторов, т.е множества похожих  фрагментов текста, при внесении изменения в один из таких текстовых фрагментов необходимо произвести соответствующие изменения и в других ``раскопированных'' элементах во избежание нарушения консистентности информации, что усложняет процесс сопровождения документации.
Более того, существуют исследования, в которых показано, что клоны в документации могут привести к клонам в программном коде~\cite{juergens2010can}.
% Таким образом, нахождение дубликатов в документации
Соответственно, нахождение повторов в документации является актуальной проблемой, и текущие исследования лишь подтверждают утверждение~\cite{horie2010tool, poruban2014reusable, poruban2016preliminary, juergens2010can, oumaziz2017documentation}.

% Способы как ищут -> сводим к строковым алгоритмам
Важным этапом при решении задачи поиска повторов является выбор того, как будет измеряться похожесть двух текстовых фрагментов и что при выбранном подходе считать клонами.

% Существующие подходы можно разделить на несколько видов: лексикографическая похожесть, семантическая похожесть, синтаксически-лексическая похожесть и комбинация вышеперечисленных.
% К семантической похожести относятся подходы, при которых похожесть (или же расстояние между фрагментами) основывается на  их семантической близости, т.е на том, насколько одинаковый смысл несут эти фрагменты.
% Синтаксически-лексические подходы основываются на структурной и синтаксической похожести.
% При лексикографической похожести (с точностью до написания) учитывается лишь то, насколько посимвольно похожи два выбранных фрагмента.

Применение строковых алгоритмов является наиболее естественным способом решения задачи поиска повторов как в произвольном тексте, так и в программной документации.
Алгоритмы решения задач поиска наибольшей общей подпоследовательности~(\emph{LCS~--- longest common subsequence}) и выравнивания двух последовательностей~(\emph{SA~--- sequence alignment})~--- широко известные алгоритмы, которые имеют разные приложения, в том числе и к задаче поиска повторов.

\emph{LCS} и \emph{SA} измеряют насколько текстовые фрагменты похожи глобально (в общем) друг на друга. 
Интуитивно понятно, что этого бывает недостаточно, потому что часто два фрагмента бывают схожи лишь небольшой общей частью.
Решить эту проблему помогает обобщение на так называемый полулокальный случай, а именно, \emph{полулокальные задачи наибольшей общей подпоследовательности и выравнивания последовательностей} (\emph{semi-local lcs, semi-local sa})~\cite{tiskin2006all}.

Автором данного обобщения является А.\,В. Тискин.
Он внес огромный вклад в развитие теории вокруг данных задач~\cite{tiskin2015fast,tiskin2019bounded,krusche2009parallel,tiskin2006longest,tiskin2008semi,tiskin2011towards}.
В частности, им изобретены эффективные алгоритмы.
Также им пишется труд~\cite{tiskin2006all}, в котором собрана вся актуальная информация, связанная c этой теорией.



% За прошедшее десятилетие Тискиным \red{А.\,В.} была развита теория вокруг данных задач, и изобретены эффективные алгоритмы решающие поставленные задачи.

Несмотря на то, что алгоритмы имеют хорошие теоретические свойства, до конца неясно, насколько они применимы на практике к задаче поиска повторов, но
относительно недавние успехи в применении этих алгоритмов в области биоинформатики~\cite{baxter2012conserved,davies2015analysis, picot2010evolutionary} дают все основания полагать, что их можно успешно адаптировать к задаче поиска повторов в документации.
Важно отметить, что большая часть алгоритмов еще ни разу не была реализована на практике.

В данной работе рассматривается адаптация алгоритмов решения полулокальных задач  поиска наибольшей общей подпоследовательности и выравнивая строк к задачам поиска повторов в документации ПО.



В данной работе представлено решение задачи поиска повторов в документации с помощью применения и адаптации алгоритмов решения задач \emph{semi-local lcs} и \emph{semi-local sa}. Для оценки применимости решения была осуществлена реализация приложения и библиотеки алгоритмов. Апробация результатов произведена на API-документации.



\section{Обзор}
В этой главе представлен обзор предметной области, в частности работ, связанных с повторами в документации ПО, описана модель повторов, которая будет использована в дальнейшем. 
Исходя из текущих исследований, сформулированы задачи поиска повторов в документации ПО.
Также произведено исследование полулокальных задач поиска наибольшей общей подпоследовательности и выравнивания строк, описаны решающие их алгоритмы и идеи со свойствами, лежащими за ними.

\subsection{Повторы в документации ПО}\label{duplicateReport}

За последние десять лет появилось множество работ, посвященных документации ПО, в частности проблемам, связанным с наличием и выявлением в ней повторов.
% связанным с повторами. 
Одни работы посвящены эмпирическим исследованиям о количестве повторов  в различных видах документации ПО~\cite{poruban2016preliminary,juergens2010can,oumaziz2017documentation}, другие~--- фокусируются на реализации механизма переиспользования повторяющихся фрагментов информации в документации~\cite{koznov2015clone,horie2010tool,poruban2014reusable}, третьи~--- на алгоритмах и подходах поиска повторов~\cite{luciv2018detecting,luciv2019interactive,blasi2018replicomment,rago2016identifying, soto2015similarity}.

Эльмар Юргенсен и др.~\cite{juergens2010can} провели широкомасштабное исследование спецификаций требований различных проектов на предмет наличия количество повторов, содержащихся в них. 
Их исследование показало, что количество повторов может быть значительно (вплоть до 70\%). 
Стоит отметить, что они адаптировали \emph{CONQAT}\footnote{\url{https://www.cqse.eu/}}~--- инструмент предназначенный для непрерывной оценки качества документации, для поиска клонов.
В их неформальной модели, повтор~--- это часть (подстрока) спецификации, которая повторяется более двух раз, а группой считаются повторы, которые разделяют общую часть. 
Соответственно, их адаптированное решение находило лишь точные повторы.

Милан Носаль и др.~\cite{poruban2016preliminary} провели эмпирическое исследование пяти крупных  
\emph{JavaDoc} проектов, целью которого являлось проверка гипотезы о том, что комментарии к коду содержат большое количество повторов.
Саму модель повторов они определили неформально, а инструмент для нахождения повторов\footnote{CPD (copy-paste detector) инструмент на основе строкового алгоритма Рабин-Карпа, который позволяет находить только точные повторы.} адаптировали, как и авторы~\cite{juergens2010can}.
Результаты их работы подтвердили гипотезу исследования. 


Работа Мохамеда А. Умазиза и др.~\cite{oumaziz2017documentation} также относится к эмпирическому исследованию \emph{JavaDoc} проектов. 
Их работа мотивирована критической важностью документации программного кода в процессе разработки ПО.
В работе повторы рассматриваются как цельные \emph{JavaDoc} комментарии, которые встречаются в документации более одного раза, т.е рассматривается неформальная модель точных повторов.
Для нахождения повторов был адаптирован инструмент \emph{GumTree tool}\footnote{\url{https://github.com/GumTreeDiff/gumtree}},  предназначенный для анализа программного кода на основе построения синтаксических деревьев.
Результаты исследования показали, что  разработчики часто  переиспользуют части документации.
Также их исследование показало, что текущие инструменты для работы с \emph{JavaDoc} документацией не позволяют в полной мере избавиться от повторов.


%запашок
% В работе~\cite{blasi2018replicomment} авторами создан прототип инструмента \emph{RepliComment} для нахождения точных повторов в \emph{JavaDoc} документации, точнее комментариях к методам (использована неформальная модель повторов).
% Также инструмент позволяет классифицировать найденные решения, что позволило исследователям найти ряд ошибок и неточностей и, как следствие, улучшить качество документации (они отправили разработчикам список найденных ошибок и неточностей).
% В итоге,  результаты анализа нескольких проектов c помощью \emph{RepliComment} показали, что как код может иметь ``плохой запах'' (code smelss), так и комментарии к нему. 
% и его достаточно много т.е в комментариях может содержаться много повторов.

% Авторы~\cite{rago2016identifying} так же, как и~\cite{juergens2010can}, делают акцент работы на повторах в спецификации требований, в частности на повторах функциональных требований в \emph{use-case} диаграммах.
% Для анализа этого вида документации они реализовали комплексный инструмент  \emph{RegAligner}, который использует комбинированный подход для детектирования повторов.
% Подход основан на конвейерной архитектуре. 
% На первом этапе применяются техники обработки естественного языка (nlp), затем используется метод машинного обучения для трансляции результатов в промежуточный язык. Таким образом, получается множество цепочек, которые попарно выравниваются.
% \emph{ReqAligner} в силу своего подхода позволяет находить не только точные повторы, но и семантически схожие.
% Также необходимо отметить, что авторы не определили формальной модели повторов.
% Авторы провели апробацию инструмента на нескольких спецификациях, получив в результате 86\% полноту и 63\% точность.
% Их результаты апробации также подтвердили факт наличия повторов в \emph{use-case} диаграммах.


Д.\,В. Луцив и коллеги внесли большой вклад своими исследованиями в области поиска повторов в документации ПО~\cite{luciv2018detecting,luciv2018duplicate,luciv2019interactive,koznov2015clone,koznov2017duplicate,luciv2016fuzzy}. 
Они разработали комплексный инструмент \
\emph{Duplicate Finder}, позволяющий  находить повторы в документации, визуализировать их, а так же вносить изменения в исходную документацию.
Разработали формальную модель повторов в документации ПО и на ее основе создали алгоритмы для поиска повторов:  алгоритм для поиска повторов по заданному шаблону и  алгоритм для поиска групп повторов.
Формальная модель позволила им доказать ряд свойств в отношении этих алгоритмов.

Алгоритм поиска групп повторов~\cite{luciv2016fuzzy} основан на идее искусственного конструирования повторов.
Сперва находятся все точные повторы, а затем на их основе строятся группы нечетких повторов.
Такая интерпретация происхождения неточных повторов имеет право на жизнь, но она искусственна, что справедливо приводит к высокому уровню ошибок при нахождении повторов (\emph{false-positive}) в их результатах апробации.
% Про цельность?

% Несмотря на то, что представленный алгоритм обладает приемлемыми характеристиками, он игнорирует семантику выделяемых повторов, что оказывается
% важным для практических применений

Алгоритм поиска повторов по образцу~\cite{luciv2019interactive} основан на идее так называемого скользящего окна.
Сперва находятся все похожие фрагменты, а затем производится их фильтрация и сжатие.
Асимптотика алгоритма оценивается как $max(O(|t||p|^4),O(|t| \log |t|))$, где $t$~--- текст, $p$~--- шаблон.
Авторами доказана полнота алгоритма.
Несмотря на это, такая асимптотическая оценка делает его не применимым на потенциально больших данных.
Также присутствует ограничение на используемую схему подсчета похожести~--- алгоритм обладает полнотой лишь при условии использования редакционного расстояния.

Таким образом, во-первых, для различных видов документации, в частности JavaDoc  документации, задача поиска повторов является  как никогда актуальной.
Во-вторых, несмотря на большое количество работ, посвященных  данной тематике, существующие подходы и алгоритмы могут быть  улучшены как в теоретических оценках, так и на практике.
В-третьих, в работах преобладает неформальная модель повторов.
В-четвертых, исследователи помимо нахождения пар повторов, также ищут и группы повторов и осуществляют поиск повторов по образцу.


\subsection{Модель повторов в документации ПО}\label{Model}
% добавить про модели
Как было описано выше, существует множество неформальных моделей, по-разному определяющих понятие \emph{повтора} в документации ПО.
% что такое \emph{повторы}.
Можно сказать более точно, в каждой статье дается свое (авторское) видение.
Формальная модель присутствует только в работах Д.\,В. Луцива.
% моделей меньше, если не сказать немного.

В данной работе будет использована наиболее общая модель, согласно которой \emph{повтор}~--- это отношение между двумя непересекающимися фрагментами $a$ и $b$, которое задается с помощью функции похожести $g$.
Отметим, что в данной модели не накладывается никаких ограничений на функцию похожести $g$.
Например, в качестве $g$ можно выбрать функцию, которая высчитывает количество одинаковых символов в двух фрагментах и сравнивает его с каким-то пороговым значением $h$. Заметим, что в этом случае функция симметрична по отношению к своим аргументам, т.е $g(a,b) = g(b,a)$.
% Например, из того, что  фрагмент $a$ является повтором фрагмента $b$, может не следовать то, что $b$ также является повтором $a$ (функция может быть не симметрична по отношению к своим аргументам, т.е $g(a,b) \neq  g(b,a)$). 

% a->b b->c   d->c  -> a,b,c,d
% GOVNO PRAV

Набор \emph{повторов} может образовывать \emph{группу повторов}, если он удовлетворяет определенным свойствам. Иными словами, \emph{группа повторов}~--- это множество повторов, которые в совокупности удовлетворяют заданному предикату.
Предикатом может служить следующее утверждение: \emph{В графе, построенном по группе повторов, существует хотя бы одна вершина, из которой достижимы все остальные. Вершинами графа являются повторы, ребра~--- значение функции $g$  для выбранных вершин}.

% TODO/Заметим, что модель (или не может?) является частным случаем (удалить?) .

\subsection{Задачи поиска повторов в документации ПО}

Можно выделить несколько задач относящихся к поиску повторов в документации ПО:
\begin{itemize}
    \item Поиск всех \emph{повторов}
    \item Поиск \emph{групп повторов}
    \item Поиск \emph{повторов} по образцу
\end{itemize}

\textbf{Поиск всех повторов}.
Задача поиска всех пар \emph{повторов} формулируется следующим образом: \emph{Дан набор текстов $t$. В $t$ необходимо найти все пары повторов,  согласно выбранной функции похожести $g$.
}

\textbf{Поиск групп повторов}.
Задача поиска групп повторов формулируется следующим образом:
\emph{Дан набор  текстов $t$. В $t$ необходимо найти все непересекающиеся группы повторов согласно выбранной функции похожести $g$ и предикату $\gamma$}.
Эта задача является вариацией предыдущей задачи.

\textbf{Поиск по образцу}.
Задача поиска по образцу формулируется следующим образом:
\emph{Дан шаблон $p$ и набор текстов $t$. Необходимо найти все непересекающиеся повторы шаблона $p$ в  $t$ согласно выбранной функции похожести $g$}. Стоит отметить, что могут существовать разные способы разбиения на непересекающиеся повторы.

% Над набором javaDoc комментариев нужно построить группы повторов, иными словами найти такое разбиение
% Задачу поиска групп повторов в Javadoc документации
% The semi-local LCS problem represents a generalization of a well-knownLCS problem. It is defined as follows




% В данном разделе представлены базовые математические модели и
% определения, использующиеся при решении поставленной задачи, даны
% определения метрик качества стабилизации видео, которые задействованы в алгоритмах стабилизации и калибровки, а также описан метод
% сбора тестовых данных и их форма
% \subsection{Документация ПО}







% \subsubsection{Виды документации ПО}
% % табличка должна быть


\subsection{Полулокальные задачи поиска}

В этой секции будут даны общие сведения о полулокальных задачах наибольшей общей подпоследовательности и выравнивания строк.
Детальные описания задач, теорем и их доказательств могут быть найдены в ~\cite{alex2007semilocal}.

% рассказать про lcs и sa
\subsubsection{Задачи поиска наибольшей общей подпоследовательности (LCS) и выравнивания строк (SA)}

Для начала, необходимо дать определение, что такое \emph{LCS} и \emph{SA}.

\paragraph*{Задача о наибольшей общей подпоследовательности (LCS)}\mbox{}

Даны две строки $a$ и $b$ длин $m$ и $n$ соответственно.
Необходимо найти наибольшую общую подпоследовательность
%\footnote{Тоже, что и в математике.
%Подпоследовательность~--- это последовательность, которая может быть получена из другой последовательности путем удаления части ($\geq 0$) её элементов без изменения порядка следования элементов.}
 символов для строк $a$ и $b$, а именно значение длины этой подпоследовательности т.е $lcs$-значение.
Пример:
\begin{center}
    $lcs(abbba,aa)=aa$ (ее длина 2)
\end{center}
 
\paragraph*{Задача о выравнивании двух последовательностей (SA)}\mbox{}

Даны две строки $a$ и $b$ длин $m$ и $n$ соответственно.
Необходимо найти наибольшее  значение функции выравнивания двух строк ($sa$) с учетом выбранной схемы оценки $w = (w_{+}, w_{0} ,$ $w_{-})=$ (пара символов совпала, пара символов не совпала, символ выровнен по пропуску).
Схема оценки отвечает за учет стоимости выравнивания пары символов из соответствующих строк, а сама функция выравнивания определяется следующим образом:
\begin{equation}\label{formula:sa}
\begin{aligned}
    sa(a,b,w) = w_{+}k^{+} + w_{0}k^{0} + w_{-} (m + n - 2k^{+} - 2k^{0}) =\\
    k^{+} (w_{+} - 2w_{-} ) + k^{0}  (w_{0} - 2w_{-}) + w_{-}(m + n),
\end{aligned}
\end{equation}


где $k^{+}$ и $k^{0}$~--- количество совпадающих и несовпадающих пар символов в выравнивании.


Иными словами, когда две строки выровнены, пара соответствующих символов $\gamma$ из $a$ и $\beta$  из $b$ будет называться выровненной.
Символы в паре могут совпасть ($w_{+}$), а могут быть различны ($w_{0}$).
Также при выравнивании символ одной строки может  быть выровнен не по символу из другой строки, а по так называемому пропуску ($gap$, $w_{-}$), т.е при выравнивании происходит разрыв и ставится пропуск '-'.
Пример выравнивания для строк $a=ABCA$, $b=ACBA$ и схемы оценки $w = (1, -0.3, -0.5)$:
\begin{center}
    \begin{tabular}{ccccc}
    A & - & B &  C  &  A \\
    A & C & B &  - &  A
    \end{tabular}
\end{center}
Здесь результат выравнивания будет равен $sa(a,b) = 3*1.0-2*0.5 = 2.0$.

Заметим, что задача поиска наибольшей подпоследовательности (LCS) является частным случаем задачи выравнивания строк (SA) при схеме подсчёта $(1,0,0)$.

Обе описанные задачи решаются динамическим программированием
и имеют сложность $O(mn)$~\cite{huang1994global}.
% Заметим, что обе задачи сводятся к поиску на прямоугольной решетке (графе) пути между  наибольшего значения  ${\color{red} Вставить картинку   }$.

Как было отмечено во введении, LCS  и SA позволяют найти насколько в глобальном смысле похожи заданные строки.
Во многих задачах интересны так называемые локальные и полулокальные случаи.
Локальный случай относится к нахождению таких пар участков из $a$ и $b$, которые максимально похожи друг на друга.
Описание полулокальных задач дано ниже.
% Полулокальный же вариант --- это, то , что лежит между глобальным и полностью локальным случаем.
% \begin{algorithm}
% \caption{Префикс SA (LCS)}\label{alg:lcssa}
% Вход: строки $a$ и $b$ длин $m$ и $n$ соответственно\\
% Выход: наибольшее значение функции \emph{sa} (\emph{lcs}) для всех пар префиксов, в частности для $a[0:n]$ и $b[0:n]$\\
% Комментарии: матрица $h$ хранит соответствующие значения т.е элемент матрицы $h[i,j]$ хранит наибольшее значение \emph{sa} (\emph{lcs}) для префиксов строк $a[0:i]$ и  $b[0:j]$\\
% Псевдокод: 
% \begin{algorithmic}[1]
% \State $h[0, j] := 0$ для всех $j \in 0..n$ 
% \State $h[i, 0] := 0$ для всех $i \in 0..m$
% \For{i in 0...m}
% \For{j in 0 ..n}
% \State $h[i,j] := max \begin{cases}
% 			h[i-1,j-1] +  
% 			\begin{cases}
% 			w_{+}, & \text{если $a[i]= b[j]$} \\
% 			w_{0}, &  \text{если $a[i]\neq b[j]$}
% 			\end{cases}, & \text{} \\
%             h[i-1,j] + w_{-}, & \text{} \\
%             h[i,j-1] + w_{-}, & \text{}
% 		 \end{cases}$
% \EndFor
% \EndFor
% \end{algorithmic}
% \end{algorithm}


\subsubsection{Semi-local LCS и SA}

% Semi-local LCS def
\paragraph*{Задача поиска полулокальной наибольшей общей подпоследовательности (semi-local lcs)}\mbox{}

Даны две строки $a$ и $b$ длин $m$ и $n$ соответственно. 
Необходимо найти значение $lcs$ для следующих подзадач:
\begin{itemize}
    \item \textbf{string-subtring}: для каждой из подстрок строки $b$ найти наибольшую общую подпоследовательность со строкой $a$, а именно значение $lcs$;
    \item \textbf{subtring-string} для каждой из подстрок строки $a$ найти наибольшую общую подпоследовательность со строкой $b$, а именно значение $lcs$;
    \item \textbf{prefix-suffix} для каждой пары, состоящей из префикса строки $a$ и суффикса строки $b$, найти наибольшую общую подпоследовательность;
    \item \textbf{suffix-prefix} для каждой пары, состоящей из префикса строки $b$ и суффикса строки $a$, найти наибольшую общую подпоследовательность.
\end{itemize}

Решение данной задачи представляется в виде квадратной матрицы $H_{a,b}$, где каждый квадрант отвечает за одну из описанных подзадач: 
\begin{equation}
 H_{a,b} = \begin{bmatrix}
suffix-prefix & substring-string \\
string-substring & prefix-suffix 
\end{bmatrix}    
\end{equation}

Более того, каждая ячейка содержит ответ для заданной пары подстрок.
Таким образом, сразу очевиден наивный алгоритм решения  задачи~--- последовательное  заполнении ячеек матрицы, что в худшем случае дает $O((n+m)^2) \times O((n+m)^2) = O((n+ m)^4)  $ сложность.

Оказывается, разработанная теория вокруг  данной задачи позволяет ее решать намного быстрее.
Точнее, существует несколько алгоритмов, имеющих асимптотику $O(n \times m)$ и $O(n \times m \times \log n)$ соответственно.
Данные алгоритмы опираются на свойствах матрицы $H_{a,b}$, которыми она обладает.


% Все они основаны на свойствах матрицы $H_{a,b}$ и теоремах связанных  с ней.

Во-первых, по построению, матрица относится к классу так называемых  \emph{юнит aнти-матриц Монжа} (\emph{unit anti-Monge}).
Матрица $H$ называется (анти-)матрицей Монжа, если выполняется следующее:
\begin{equation}
    H[i, j] + H[i^{'},j^{'}] \leq(\geq) H[i', j] + H[i,j'] ,\quad \forall \: i \leq i' , j \leq j'
\end{equation}
(Анти-)матрица Монжа $H$ называется \emph{юнит (анти)-матрицей Монжа}, если матрица (-)$H^{\msquare}$, получающаяся в результате взятия перекрестной разности анти-диагонали и диагонали для всех смежных квадратов 2 на 2,   является перестановочной. Пример \emph{юнит матрицы Монжа} (первая матрица):
\begin{equation}
\begin{bmatrix}
0 & 2 & 3 \\
0 & 1 & 2 \\
0 & 1 & 1
\end{bmatrix} ^ { \msquare} =
\begin{bmatrix}
(2 + 0) - (1 + 0)  & (3 + 1) - (2 + 2)  \\
(1 + 0) - (1 + 0) &  (2 + 1) - (1 + 1) 
\end{bmatrix} = 
\begin{bmatrix}
1 & 0  \\
0 & 1 
\end{bmatrix} 
\end{equation}


Во-вторых, данный класс матриц образует моноид с операцией $\otimes$ над этими матрицами, которая известна как \emph{distance matrix multipliсation}\footnote{Операция над матрицами в тропической алгебре. Это обычное матричное умножение, в котором умножение (*) заменено на сложение (+), а сложение (+) - на взятие минимума (min).}.

В-третьих, доказано~\cite{tiskin2006all}, что можно произвести декомпозицию данных матриц и хранить их неявно в виде перестановочных матриц  $P_{a,b}$ (так называемое ядро матрицы $H_{a,b}$), что позволяет существенно сократить объем используемой памяти.
Эти ядра также образуют моноид, называемый \emph{моноидом липких кос}, для которых также определена своя операция умножения $\odot$.
Удивительным образом, эти два моноида изоморфны друг другу~\cite{tiskin2006all}, что позволяет использовать $\odot$ вместо $\otimes$. 
Иными словами, для того, чтобы посчитать произведение двух монжевых матриц, можно перейти к косам, произвести над ними операцию $\odot$, тем самым получив результат исходной задачи (справедливо и обратное для липких кос и операции $\otimes$).
    
В-четвертых, доказано~\cite{tiskin2006all}, что  ядро $P_{a,b}$ может быть выражено через конкатенацию двух меньших решений:
\begin{equation}\label{formulaKernelCompistion}
P_{a,b}  = P_{a^{'},b} \odot P_{a^{''},b}, a  := a^{'}a^{''}
\end{equation}
Это позволяет использовать известный принцип \emph{разделяй и властвуй}.

Стоит отметить, что А.\,B. Тискиным изобретен быстрый алгоритм для перемножения двух липких кос~--- \emph{алгоритм муравья}~\cite{tiskin2015fast}, имеющий асимптотику $O(n\times \log n)$, где $n$~--- количество ненулевых элементов в перестановочной матрице.
Однако неясно, насколько практическая реализация будет эффективна.

Из всего вышесказанного сразу вытекают следующие два рекурсивных алгоритма, основанные на умножении липких кос  и монжевого матричного умножения через $\otimes$~\cite{tiskin2008semi}.
% algo implitic
% \begin{algorithm}[h]
% \caption{Рекурсивный алгоритм для решения semi-local lcs через липкое умножение кос}\label{alg:ant}
% Вход: строки $a$ и $b$ длин $m$ и $n$ соответственно\\
% Выход: ядро  матрицы $H_{a,b}$\\
% Комментарии: Сложность алгоритма $O(n \times m)$\\
% Псевдокод:

% % , не имеет практической реализации
% \begin{algorithmic}[1]
% \If {$n=1$ и $m=1$}    \Comment{База рекурсии, длина строк 1}
%     \If{$a=b$}
%         \State Вернуть ядро  $2 \times 2$, отвечающее диагональной
%         \par\hskip\algorithmicindent
%         единичной матрице
%     \Else
%         \State Вернуть ядро размера 2 на 2, отвечающее антидиагональной 
%         \par\hskip\algorithmicindent единичной матрице
%     \EndIf
% \Else
%     \State Выбрать строку с наибольшей длиной
%     \State Разбить её на конкатенацию двух подстрок
%     \State Рекурсивно запустить алгоритм над этими двумя половинами
%     \State Произвести конкатенацию решений через  $\odot$     
%     \State Вернуть полученное решение
% \EndIf
% \end{algorithmic}
% % Стоит отметить, что неизвестно, насколько данный алгоритм эффективен на практике, поскольку он не не имеет практической реализации.
% \end{algorithm}
% algos explciit
% \begin{algorithm}[h]
% \caption{Рекурсивный алгоритм для решения semi-local lcs через явное умножение матриц}\label{alg:monge}
% Вход: строки $a$ и $b$ длин $m$ и $n$ соответственно\\
% Выход:  матрица $H_{a,b}$\\
% Комментарии: Сложность алгоритма $O(n \times m \times \log n)$\\
% Псевдокод:

% \begin{algorithmic}[1]
% \If {$n=1$ и $m=1$}    \Comment{База рекурсии, длина строк 1}
%     \If{$a=b$}
%         \State Вернуть матрицу, которой отвечает ядро размера 2 на 2,
%         \par\hskip\algorithmicindent единичная диагональная матрица
%     \Else
%         \State Вернуть матрицу, которой отвечает ядро размера 2 на 2,
%         \par\hskip\algorithmicindent единичная анти-диагональная матрица
%     \EndIf
% \Else
%     \State Выбрать строку с наибольшей длиной
%     \State Разбить её на конкатенацию двух подстрок
%     \State Рекурсивно запустить алгоритм над этими двумя половинами
%     \State Произвести конкатенацию найденный решений через  $\otimes$ 
%     % (умножение через алгоритм swamk )
%     \State Вернуть полученное решение
% \EndIf
% \end{algorithmic}
% \end{algorithm}

% В силу того, что матрица $H$--- уни анти монжева, и выполняется (5), и благодаря изоморфизму можно восопльзоваться быстрым умножением монжевых матриц котороые основано на smawk алгоритме.
% Это позволяет добиться сложности $O(n \times m)$.

Также существует итеративный алгоритм, имеющий асимптотическую сложность $O(n \times m)$, основанный на распутывании кос\footnote{С каждой перестановочной матрицей размера $n \times n$ ассоциирована \emph{сокращенная липкая коса} (\emph{reduced sticky braid}). Одной \emph{сокращенной липкой косе} соответствует бесконечное множество липких кос. Таким образом, произвольную липкую косу можно  \emph{распутать} до  (свести к) \emph{сокращенной липкой косе}, которой уже будет отвечать ядро $P_{a,b}$.
}.

% Факт того, что ядро $P_{a,b}$ относится к \emph{моноиду липких кос}, позволяет решить задачу \emph{semi-local lcs} неявно через операцию распутывания кос, которая 
% через так называемое сведение косы к 



% Также, из-за того, что 
% существует итеративный алгоритм, основанный на том факте, что \emph{липкую косу}, можно встроить в  

% Также стоит упомянуть, известный еще с годов итеративный алгоритм~\cite{alavaes}, который также позволяет решить задачу за $O(n \times m)$  

Еще раз отметим, что для простоты изложения некоторые детали при описании опущены для упрощения. Детальное описание можно найти в ~\cite{alex2007semilocal}, как было отмечено выше.

% Таким образом, часть из упомянутых  алгоритмов позволяют решать за ту же асимптотику что и обычный \emph{lcs}.

%  рассказать про semi local

% Аналогичным образом присутствует обобщение на полулокальную версию выравнивания строк  (semi-local sa).


% Semi-local SA def
\paragraph*{Задача поиска полулокального выравнивания двух строк (semi-local sa)}\mbox{}

Даны две строки $a$ и $b$ длин $m$ и $n$ соответственно и схема оценки $w = (w_{+}, w_{0} , w_{-})$. 
Необходимо найти значение выравнивания ($sa$) для следующих подзадач:
\begin{itemize}
    \item \textbf{string-subtring}: для каждой из подстрок строки $b$ найти максимальное выравнивание со строкой $a$; 
    \item \textbf{subtring-string}: для каждой из подстрок строки $a$ найти максимальное выравнивание со строкой $b$; 
    \item \textbf{prefix-suffix}: для каждой пары, состоящей из префикса строки $a$ и суффикса строки $b$, найти максимальное выравнивание; 
    \item \textbf{suffix-prefix}: для каждой пары, состоящей из префикса строки $b$ и суффикса строки $a$, найти максимальное выравнивание. 
\end{itemize}
% описать аолгори
Подход для решения этой задачи заключается в следующем.
Заметим, что  схему оценки в  формуле (\ref{formula:sa}) можно свести (нормализовать) к $регулярной схеме оценки$ $w^{'} = (1,\frac{\mu}{v} ,0)$:
\begin{equation}\label{weightNormalization}
    \begin{aligned}
    w = (w_{+}, w_{0} , w_{-}) \xrightarrow{} (w_{+} +2x , w_{0} + 2x , w_{-} + x) =\\ ( \frac{w_{+} +2x}{w_{+} +2x} , \frac {w_{0} + 2x}{w_{+} +2x} , \frac{w_{-} + x}{w_{+} +2x})_{x=-w_{-}} = (1,\frac{\mu}{v} ,0) 
    \end{aligned}
\end{equation}
Тогда для того, чтобы получить значение $sa$, при  известном $sa_{normalized}$ нужно применить обратную регуляризацию:
\begin{equation}
    \begin{aligned}
    sa(a,b,w) = sa_{normalized}  (w_{+} - 2w_{-}) +  w_{-} (m + n)
    \end{aligned}
\end{equation}

Сведение схемы оценки к \emph{регулярной} позволяет уменьшить количество параметров.
Это, в свою очередь, позволяет решить задачу $semi-local$ $sa$ следующим образом\footnote{Детали доказательств и сведений ~\cite{tiskin2006all}.}. 
При использовании техники $blown-up$\footnote{Исходные задача увеличивается в $v^2$ раз и сводится к задаче \emph{semi-local lcs}.} асимптотика решения через  итеративный алгоритм увеличится в $v^2$ раз до $O(m \times n \times v^2)$.
Структура рекурсивного алгоритма через умножение кос позволяет добиться линейной зависимости от параметра $v$. 

При большом значении параметра становится выгоднее использовать алгоритм, который не зависит от схемы оценки и не ``раздувает'' задачу. 
В данном случае идет речь об описанном ранее алгоритме решения через матричное умножение $\otimes$ (применяется без существенных изменений шагов алгоритма). 
В этом случае асимптотика решения не зависит от $v$ и будет $O(  n \times m \times \log n)$.

\vspace{4 mm}
\noindentВ конце обзора необходимо отметить, что матрица $H_{a,b}$ содержит большое количество информации, что позволяет решать такие задачи, как $ThresholdAMatch$, $WindowAMatch$, $FragmentSubstring$, $WindowSubsring$, $Smith-Waterman$  $alignment$ и др.
Часть из них будет описаны в соответствующих разделах, относящихся к реализациям алгоритмов для поиска повторов.

Таким образом, реализация большей части алгоритмов, связанных с данной теорией, представляет интерес как с точки зрения инженерной задачи, так и со стороны научного исследования.
\begin{itemize}
    \item Алгоритмы обладают хорошими  теоретическими свойствами, но большая часть из них не имеет практической реализации~--- неясно насколько они применимы на практике.
    \item Могут ли алгоритмы, решающие задачи \emph{semi-local}, быть адаптированы и успешно применены к области поиска повторов в документации ПО?
\end{itemize}

%  про существующие вариации задач boudnend length и пр


\section{Реализация библиотеки алгоритмов для полулокальных задач}\label{librarySection}
Как было отмечено в обзоре полулокальных задач,
существует необходимость в реализации большей части алгоритмов.
% В данном разделе будет описана реализация и архитектура библиотеки алгоритмов, связанных с полулокальными задачами.

% В качестве языка программирования был выбран \emph{Kotlin}

\subsection{Архитектура библиотеки}
В качестве языка программирования для написания библиотеки был выбран язык \emph{Kotlin}.

Код библиотеки можно  разделить на два логических модуля:
\begin{itemize}
    \item модуль \emph{semilocalProblem}  (Рис.~\ref{fig:libraryProblem}),
    \item модуль \emph{semilocalApplication} (Рис.~\ref{fig:libraryApplication}).
\end{itemize}


\subsubsection{Модуль semilocalProblem}
В данном модуле реализована вся логика, отвечающая за задачи \emph{semi-local}.

% умножение муравья
Интерфейс \emph{IBraidMultiplication} отвечает за алгоритмы, реализующие операцию $\odot$, в частности, алгоритм \emph{муравья}.
В ходе работы алгоритма происходит последовательный доступ к перестановочным матрицам, к которым применен оператор $^{\nearrow}$ и $^{\swarrow}$\footnote{Оператор $^{\nearrow}$ ($^{\swarrow}$)  подсчитывает сумму элементов, которые лежат левее (правее) и ниже (выше) выбранного узла в матрице.}.
Для достижения быстрого времени доступа к элементам  матрицы ($O(1)$) используется
класс \emph{CountingQuery}, инкапсулирующий эту логику\footnote{Теорема 1 в~\cite{tiskin2015fast}.}.
% 
Хранение перестановочных матриц реализовано с помощью хранения двух перестановок, отвечающим строчкам и столбцам матрицы.
Для реализации иной логики хранения необходимо реализовать методы абстрактного класса $AbstractPermuation-Matrix$.

Классы, реализующие интерфейс \emph{ISemiLocalCombined}, инкапсулируют всю логику, связанную с задачей $semi-local$.
В частности, \emph{ImplicitSemiLocalSA} инкапсулирует логику по неявному хранению матрицы, отвечающей задаче \emph{semi-local}, в виде \emph{ядра $P$} и соответствующими алгоритмами над ним.
На данный момент такими алгоритмами являются описанные в обзоре рекурсивный алгоритм с операцией $\odot$ и итеративный алгоритм распутывания кос.
Стоит отметить, что для быстрого доступа к произвольному элементу матрицы  используется интервальное двумерное дерево (\emph{range tree}), построенное над ненулевыми элементами ядра.
Это позволяет сократить объем требующейся памяти, но требует неконстантного времени доступа к элементам.
В случае если доступ последовательный, используется  \emph{CountingQuery}, который позволяет добиться константной асимптотической сложности.

\begin{figure}
  \centering
  \includegraphics[height=0.72\columnwidth,angle=90]{Mishin/figures/Library.png}
  \caption{Диаграмма классов UML части библиотеки, относящейся к различным задачам, основанным на  \emph{semi-local} задачах; Часть деталей и классов опущена}\label{fig:libraryProblem}
\end{figure}

\emph{ExplicitSemiLocalSA} хранит матрицу $H_{a,b}$ в явном виде.
В данном случае нет экономии памяти, но доступ к произвольному элементу матрицы константный $O(1)$. 
Для решения задачи \emph{semi-local} используется алгоритм \emph{smawk}~\cite{aggarwal1987geometric}, отвечающий операции  $\otimes$.

% Стоит отметить, что недавние исследования~\cite{gawrychowski2020submatrix}, позволяют добиться 
% Нужно ли описать scorinSCheme



% \emph{ISemiLocalProvider}, \emph{ISemiLocalCombined} === паттерн фабричный метод
% набор классов и интерфейсов связанных с \emph{}
% Strategy --- стратегия




\subsubsection{Модуль semilocalApplication}
В данном модуле реализованы алгоритмы\footnote{Детальное описание алгоритмов и их доказательств можно найти в~\cite{tiskin2006all}.}, для следующих задач:
\begin{enumerate}
    \item \emph{CompleteAMatch}
    \item \emph{Minimal-inclusive ThresholdAMatch}
    \item \emph{WindowAMatch}
    \item \emph{WindowSubstring}
    \item \emph{FragmentSubstring}
    \item \emph{BoundedLengthSmithWatermanAlignment}
\end{enumerate}

Первая задача относится к нахождению значения максимального выравнивания заданного шаблона $p$ и всех префиксов текста $t$ из всевозможных суффиксов из данного префикса:
\begin{equation}
    h[j] = \max _{i \in 0 ..j} sa(p,t[i,j]), j \in 0..|t|
\end{equation}

В рамках второй задачи ставится задача нахождения всех непересекающихся повторов шаблона $p$ в тексте $t$, чьи длины минимальны, а значение выравнивания выше заданного порога похожести $h$.

В третьей задаче необходимо найти все подстроки текста $t$ (уже могут пересекаться) длины $w$, чье выравнивание с шаблоном $p$ больше заданного порога похожести $h$.

Все эти три задачи сводятся к анализу \emph{подматрицы} задачи 
\emph{semi-local}, отвечающей \emph{srting-substring}.
И, соответственно, в зависимости от выбранного алгоритма решения задачи \emph{semi-local} асимптотика алгоритмов решения этих задач $O(n \times m \times \log n)$ и $O(v \times  m \times n)$.


\begin{figure}
    \includegraphics[width=\columnwidth]{Mishin/figures/semiLocalApplication.png}
    \caption{Диаграмма классов UML части библиотеки, относящейся к \emph{semi-local} задачам. Часть деталей и классов опущена}\label{fig:libraryApplication}
\end{figure}


Задача \emph{FragmentSubstring} формулируется следующим образом: Для заданного множества интервалов (подстрок) $r$ из текста $t$ размера $m$ и текста $b$ размера $n$ необходимо вычислить \emph{semi-local} матрицу для каждого фрагмента из $r$ против $b$.
Имеет асимптотическую сложность $O(v^2 \times r \times  n \times \log m \times \log mv)$ \footnote{Существует возможность улучшить асиптотику до $O(v \times r \times  n \times \log^{2} m)$.} и $O(r \times n \times m  \times  log m)$.

Задача \emph{WindowSubstring}  является частным случаем   \emph{FragmentSubstring}, в которой размер фрагментов фиксирован.
Асимптотическая сложность решения уже будет $O(n \times m \times \log n)$ и $O(v^2 \times  m \times n)$.

Обе задачи основаны на двоичном разложении числа и предподсчете \emph{semi-local} решений, отвечающих данным разложениям.

Задача \emph{SmithWatermanAlignment} относится к локальному выравниванию.
В рамках данной задачи необходимо вычислить значение максимального локального выравнивания между $a$ и $b$, т.е найти пару подстрок, на которых достигается максимальное выравнивание.
Очень часто данная задача представляет интерес с различными ограничениями~\cite{arslan2004dynamic}.
Например, ограничения на минимальную длину подстрок.
Данное ограничение реализовано с помощью алгоритма из ~\cite{tiskin2019bounded} и инкапсулировано в соответствующем классе  \emph{BoundedLength-\\SmithWatermanAlignment}.
% Нетрудно заметить, что часть алгоритмов в той или иной степени может быть адаптирована к задачам поиска повторов в документации.
% Для задачи поиска по образцу такими кандидатами являются алгоритмы для решения задачи \emph{Minimal-inclusive ThresholdAMatch} и \emph{WindowSubstring}.
% Для задачи поиска групп повторов могут быть применены  алгоритмы для \emph{WindowAMatch},
% \emph{Minimal-inclusive ThresholdAMatch}, \emph{BoundedLengthSmithWatermanAlignment} и \emph{semi-local}.

% Адаптация алгоритмов к поиску повторов описана в следующем разделе.
% Экспериментальная проверка асимптотики части алгоритмов, а так же их потенциальная возможность применения к большим данным даны в главе~\ref{appob}.

% Соответствующая адаптация части алгоритмов описана в следующем разделе.


\section{Приложение для поиска повторов в документации ПО}\label{searchPO}
В данной главе  описано приложение для поиска повторов в документации ПО, в рамках которого будет производится экспериментальное исследование применимости алгоритмов, решающих полулокальные задачи.
Также описаны  основные технические решения и архитектура.
Описан подходы для поиска повтор.
Для каждой из \emph{задач поиска повторов} описано решение, основанное на использовании \emph{библиотеки алгоритмов} для полулокальных задач (см. главу~\ref{librarySection}).

% Реализация приложения для поиска повторов в JavaDoc докумен-тации с применением алгоритмов решения полулокальных задач


\subsection{Общая архитектура приложения}
На рисунке~\ref{fig:application} представлена архитектура приложения.
Оно реализовано в виде двух крупных компонент.

\begin{figure}[H]
    \includegraphics[width=\columnwidth]{Mishin/figures/arhitecture.png}
    \caption{Диаграмма компонентов системы}\label{fig:application}
\end{figure}


Первая компонента (клиентская часть)~--- это пользовательский интерфейс (\emph{UI}), который  отвечает за визуализацию и взаимодействие с пользователем.
Пользователь настраивает параметры поиска повторов, тип поиска, указывает файлы, в которых необходимо произвести анализ на дубликаты, или путь к проекту на \emph{Github} в интернете (Рис.~\ref{fig:startApp}).
Клиентская часть написана на \emph{python} и \emph{java script}.
Детальное описание клиентской части дано в секции~\ref{clinet}.

Вторая компонента (серверная часть) отвечает за поиск повторов согласно заданным настройкам.
Данная часть написана на языке \emph{Kotlin}.
В секции~\ref{server} детально описана функциональность данной части системы.

Взаимодействие между компонентами осуществляется посредством \emph{JSON}-формата.
Приложение реализовано в виде вэб-приложения, которое запускается в докер-контейнере, что минимизирует пользовательские требования для запуска программы\footnote{Достаточно иметь \emph{Docker} и \emph{Браузер}.}.

% Приложение реализовано в виде вэб-сервиса, который запускается в докер-контейнере на пользовательском компьюетере.



Стоит отметить, что в этой работе сделан основной акцент на поиск повторов в \emph{JavaDoc} документации в силу её актуальности для данного формата (см. главу~\ref{duplicateReport}).

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{Mishin/figures/startApp.png}
    \caption{Интерфейс пользователя перед запуском анализатора для случая поиска групп повторов}\label{fig:startApp}
\end{figure}

\subsection{Клиентская часть}\label{clinet}
Как было отмечено выше, клиентская часть реализована в виде веб-приложения, которое написано посредством \emph{python}-фреймворка \emph{flask}\footnote{\url{https://flask.palletsprojects.com/en/1.1.x/}~--- микро-фрейм\-ворк для написания веб-приложений.}.
На основной странице вэб-приложения пользователь выставляет тип решаемой задачи, параметры запуска, указывает исходники и запускает вычисления.
Пользователь имеет возможность выбрать задачу \emph{``Поиск повтора по шаблону''} или \emph{``Поиск всех групп повторов''}.

Для визуализации найденных повторов в случае с  \emph{``Поиском повтора по шаблону''} результаты отображаются на странице ответа с цветовой расцветкой.
% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.5\columnwidth]{Mishin/figures/outputExampleAmatch.png}
%     \caption{Визуализация найденных повторов для поиска по шаблону}\label{fig:pattViz}
% \end{figure}
Для групп повторов механизм визуализации более комплексный (см. рис~\ref{fig:groupViz}): используется три окна для интерпретации результатов.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\columnwidth]{Mishin/figures/outputGroup.png}
    \caption{Визуализация групп повторов}\label{fig:groupViz}
\end{figure}


Первое окно отвечает за отображение отношений между фрагментами, которые состоят в отношении (имеют похожие части).
Интерпретация следующая: для текущего узла ``родителем'' являются все те фрагменты, в которые была взята часть информации с текущего фрагмента и, возможно, видоизменена.
``Детьми'' являются те фрагменты, c которых, вероятнее всего, произошло дублирование информации.

Второе окно отвечает за представление каждого повтора в виде иерархической структуры.
Представление реализовано в виде \emph{tree control}~--- для каждого повтора (вершины) строится ориентированное дерево вывода из этой вершины.
Такая интерпретация показывает, откуда вероятнее всего ``произошел повтор'', т.е откуда произошло дублирование данных.

Третье окно отвечает за визуализацию соответствующей группы повторов в  виде ориентированного графа.
Это позволяет увидеть структуру найденной группы. Все три окна синхронизированы между собой.

Описание используемых алгоритмов для нахождения повторов даны в секциях~\ref{fics} и~\ref{grouppa}  соответственно.    


% Рассмотрим пример работы  на рис~\ref{TODO}. TODO описать пример. 

\subsection{Серверная часть}\label{server}
Как было указано выше, эта часть приложения отвечает за поиск повторов в документации.

На Рис.~\ref{fig:application} выделены компоненты серверной части (\emph{Kotlin application}).
Общий подход (\emph{pipeline}) поиска повторов заключается в следующем.

Сперва происходит синтаксический анализ с целью нахождения тех фрагментов, которые будут анализироваться согласно выбранным параметрам, заданными пользователем.
В данной работе анализируются \emph{JavaDoc} документация, а именно \emph{JavaDoc}-комментарии методов, классов и интерфейсов.
Это осуществлено с использованием библиотеки \emph{JavaParser}\footnote{\url{https://javaparser.org/}}.
Для анализа иного вида документации (например, обычный текст, как в случае с поиском по образцу) достаточно в модуле \emph{Parser} реализовать необходимые интерфейсы.
Далее, комментарии обрабатываются различными фильтрами~--- происходит токенизация, лемматизация, убираются стоп-слова и пр.


Данная обработка происходит с частичным использованием функциональности стэнфордского  фреймворка \emph{core nlp}\footnote{\url{https://stanfordnlp.github.io/CoreNLP/}} для обработки естественного языка.

После этапа предобработки фрагментов происходит конвертация слов  в промежуточное представление в виде чисел с целью экономии памяти и ускорения работы алгоритмов.

Затем  происходит запуск соответствующих алгоритмов поиска, о которых пойдет речь дальше.


\subsection{Алгоритмы для решения задачи поиска повторов}\label{fics}
% fix

В данной секции будут описаны алгоритмы для решения задачи поиска по образцу, согласующиеся с определенной моделью в главе~\ref{Model}.
Алгоритмы основаны на использовании \emph{библиотеки алгоритмов} (см. главу~\ref{librarySection}).


\subsubsection{Улучшенный алгоритм интерактивного поиска}
В данной секции описана улучшенная версия алгоритма из~\cite{luciv2019interactive}. Псевдокод алгоритма представлен ниже (алгоритм~\ref{alg:patternMathing1}).

\begin{algorithm}[t!]
\caption{Нечеткий поиск по шаблону с использованием semi-local}\label{alg:patternMathing1}
Вход: шаблона поиска $p$, текст $t$, пороговое значение похожести $k$\\
Выход: множество непересекающихся повторов шаблона $p$\\
Комментарии:
\begin{equation}
    k_{di}=|p|*(\frac{1}{k}+1)(1-k^2)
\end{equation}
Псевдокод:
\begin{algorithmic}[1]
\State $W = semilocalsa(p,t)$\Comment{1 фаза}
\State $ H^{str-sub}_{p,t} =  W.stringSubstringMatrix()$
\State $ M[j,i] = H^{str-sub}_{p,t}[i,j] $
\State $lstW = queryWindows()$\Comment{2 фаза}
\State $W_2 = processDiagonal()$
\State $W_3 = UNIQUE(W_2)$\Comment{3 фаза без изменений}
\For{$w \in W_3$}
\If{$\exists w^{'} \in W_3:w \subset w^{'} $}
\State $remove$ $w$ $from$ $W_3$
\EndIf
\EndFor
\State $return$ $W_3$

\end{algorithmic}
\end{algorithm}

\begin{figure}[t!]
\centering
    \includegraphics[width=0.5\columnwidth]{Mishin/figures/M2.png}
    \caption{Пример обхода матрицы $M$. Трапеция соответствует всем подстрокам текста, чья длина ограничена интервалом $I$. Треугольники отвечают скользящим окнам.
    Обход происходит с конца текста.
    }\label{passage}
\end{figure}

В строках $1-3$ вычисляется решение задачи \emph{semi-local sa}, в частности, подзадачи \emph{string-substring} и происходит операция транспонирования для получения матрицы $M$.
Далее в строке $4$ для каждого окна размера $L_{w}$ вычисляется значение выравнивания с 
шаблоном $p$  и результат сохраняется в список $lstW$.
После этого обрабатывается трапеция в матрице $M$, которой отвечают все
подстроки текста $t$ с размером из интервала $I=[|p|k,\frac{|p|}{k}]$.
Она обходится таким образом, что в результате внутри каждого окна размера $L_{w}$,
чья пороговая похожесть выше заданного порога $-k_{di}$, находится подстрока с длиной из  интервала $I$, которая максимально похожа на шаблон. Если таких подстрок несколько, будет выбираться наиболее длинная (строка $5$).
Далее результат сохраняется в множество $W_{2}$
Пример обхода представлен на Рис.~\ref{passage}.

\paragraph*{Корректность улучшения}\mbox{}

Нетрудно заметить, что данная версия имеет лучшую асимптотическую сложность, чем исходный алгоритм. Более того, все свойства алгоритма сохраняются.
Исходный алгоритм разбит на три фазы: ``сканирование'', ``усушка'' и ``фильтрация''.

В первой фазе исходный текст $t$ анализируется скользящим окном размером $w_{s} = \frac{|p|}{k}$, где $k \in [\frac{1}{\sqrt{3}},1]$ параметр алгоритма, с шагом в один символ, а именно вычисляется редакционного расстояние\footnote{Метрика, минимальное количество операций вставки, удаления и замены одного символа на другой для превращения одной строки в другую.} между каждым окном и заданным шаблоном $p$.
Согласно~\cite{luciv2019interactive} асимптотическая сложность данного шага $O(|p|^2 \times |t|)$.

Заметим, что редакционное расстояние может быть выражено через выравнивание последовательностей.
Конкретнее, редакционное расстояние для данного случая выражается через следующую схему оценки:
\begin{equation}\label{weightAppr}
    (w_{+},w_{0},w_{-}) = (0,-2,-1)
\end{equation}
Соответственно, редакционное расстояние можно заменить на выравнивание последовательностей с весами $(0,-2,-1)$ и искать максимальное выравнивание без потери свойств алгоритма в силу эквивалентности двух задач.
Из этого следует, что можно применить алгоритмы для решения \emph{semi-local sa}.
В силу  формулы (\ref{weightNormalization}), значение нормализованной схемы будет следующее:
\begin{equation}
    (0, -2, -1) \rightarrow (1,\frac{\mu=0}{v=1}, 0)
\end{equation}
Таким образом, используя нормализацию, задачу можно свести к \emph{semi-local lcs}.
И, следовательно, асимптотическая сложность первой фазы алгоритма  из~\cite{luciv2019interactive} может быть улучшена. Тогда её асимптотическая сложность будет $O(|t| \times |p|)$ вместо $O(|t| \times |p|^2)$.
Данная стадия эмулируется в строке $1$.

Во второй фазе происходит так называемая ``усушка''~--- для каждого окна происходит вычисление максимальной подстроки, на которой достигается минимальное значение редакционного расстояния (в случае выравнивания последовательностей это относится к максимальному значению).
При равенстве расстояний выбирается подстрока наибольшая по длине из интервала $I$.
Асимптотическая сложность данной фазы выражается как $O(|t| \times |p|^4$).

Для улучшения данной фазы применяется следующее.
Матрица решений $H_{p,t}$ содержит подматрицу \emph{string-substring} ($H^{str-sub}_{p,t}$), которая содержит значения выравнивания шаблона $p$ со всеми подстроками текста $t$.
После применения операции транспонирования к матрице $H^{str-sub}_{p,t}$ получается матрица $M$, в которой присутствует трапеция, которая отвечает всем подстрокам текста $t$ с длиной из интервала $I$ (Рис.~\ref{passage}).
Алгоритм обхода представлен на Рис.~\ref{passage}.
В силу того, что во время обхода посещаются смежные ячейки, асимптотическая сложность доступа к матрице $O(1)$ согласно~\cite{tiskin2008semi}.
Всего будет посещено $O((\frac{|p|}{k}-|p|k)*|t|)=O(|p|\times|t|)$ ячеек.
В рамках обхода мы будем поддерживать список $rowMax$ из $O(p)$ элементов в котором будут содержаться наибольшие подстроки с максимальным выравниванием для текущих префиксов (отвечает строкам, черный треугольник на Рис.~\ref{passage}).
При очередном  проходе столба в трапеции мы обновим максимумы для строк (текущее обозреваемое окно, треугольник) с учетом сдвига на единицу (последняя строка уходит, появляется новая из одного элемента~--- на Рис.~\ref{passage} после сдвига по диагонали добавится строка, а снизу удалится строка полностью).
Далее мы проверяем, что значение выравнивания окна размером $L_{w}$ выше порога $-k_{di}$, отвечающее текущему треугольнику. Для этого мы просто проверяем элемент списка $lstW$, отвечающий этому окну.
Если значение выше порогового, тогда наиболее длинная подстрока с максимальным выравниванием сохраняется в множество $W_{2}$.
Соответственно, асимптотическая сложность обработки каждого столбца (каждого треугольника)  $O(|p|)$.
Таких столбцов $|t|$ штук.
Таким образом, асимптотическая сложность всей второй фазы $O(|t| \times |p|)$.

Значит, асимптотическая сложность второй фазы $O(|p| \times |t|)$, все свойства алгоритма сохранены.

Третья фаза, отвечающая за фильтрацию фрагментов, остается без изменений. Ее асимптотическая сложность $O(|p| \times \log |p|)$ согласно~\cite{luciv2019interactive}.
Соответственно, алгоритм сохранит все свои свойства и будет уже иметь асимптотику $O(|p| \times |t|)$.
% Как отмечено выше, псевдокод алгоритма представлен на ~\ref{alg:patternMathing1}.

\subsubsection{Алгоритм нечеткого поиска шаблона с использованием ThresholdAMatch}
Более простое решение относится к алгоритму~\ref{alg:patternMathing2}, реализация которого уже содержится в \emph{библиотеке алгоритмов}. 
Он позволяет найти все непересекающиеся повторы шаблона $p$ в тексте $t$.

Сперва решается задача \emph{CompleteAMatch}, в рамках которой для каждого столбца $j$ подматрицы \emph{string-substring} находится максимальное значение и позиция $(i,j')$, в которой оно  достигается, т.е находится суффикс префикса, который больше всего похож на шаблон.
Далее, над полученным результатом производится фильтрация, начиная с конца.
В результате чего остаются только непересекающиеся повторы минимальной длины, которые больше заданного порога похожести.
Асимптотическая сложность данного решения зависит от выбранного алгоритма  решения \emph{semi-local}.
Соответственно, $O(|t| \times |p| \times \log |t|)$, $O(|t| \times |p| \times v^2)$ или $O(|t| \times |p| \times v)$.

Данный алгоритм рассматривается как альтернатива алгоритму~\ref{alg:patternMathing1}.

\begin{algorithm}[b!]
\caption{Нечеткий поиск по шаблону с использованием Min-inclusive ThresholdAMatch}\label{alg:patternMathing2}
Вход: шаблона поиска $p$, текст $t$, пороговое значение похожести $h$\\
Выход: множество непересекающихся повторов шаблона $p$\\
Псевдокод:
\begin{algorithmic}[1]
\State $maxSuffixes= CompleteAMatch(p,t)$
\State $reverse(maxSuffixes)$
\State $result = \emptyset$
\For{$(i,j,score) \in maxSuffixes$}
   \If{$score \geq h \& j \leq res.last().i $} 
    \State $res.add((i,j,score))$ 
    \EndIf
\EndFor
\State $return$ $result$

\end{algorithmic}
\end{algorithm}

% \subsubsection{Алгоритм нечеткого поиска шаблона с использованием Разреза}

% Еще одним решением на основе \emph{semi-local} является следующий алгоритм.
% Во-первых, задачу поиска по шаблону можно сформулировать с иной точки зрения: 
% необходимо найти все максимальные по выравниванию непересекающиеся повторы шаблона $p$ в тексте $t$, т.е получить такую цепочку непересекающихся интервалов $(i_1,j_1),...,(i_n,j_n)$, что на $(i_k,j_k)$ достигается максимальная похожесть на еще непокрытой найденными интервалами части текста $t$.
% В рамках задач \emph{semi-local} это означает разбитие матрицы \emph{string-substring} на непересекающиеся подматрицы, с учетом максимумов в подматрицах.
% Последнее относится к быстрому поиску максимума в матрице (\emph{range maximum query}).
% В силу того, что матрица \emph{string-substring} является матрицей Монжа, можно применить результат из статьи ~\cite{gawrychowski2020submatrix}. 
% Для этого необходимо реализовать структуру данных, асимптотическая сложность построения которой равна $O(|t|\times \log |t|)$ (размер структуры выражается как $O(|t|)$), которая позволяет делать запросы на поиск максимума в произвольной подматрице, имеющие асимптотическую сложность $O(\log \log|t|)$.
% Учитывая, что непересекающихся повторов в тексте $t$ может быть в худшем случае $|t|$ штук,
% для их нахождения необходимо осуществить $|t|$ запросов на поиск максимуму.
% Следовательно, конечная асимптотика алгоритма $O(|t| \times \log \log t) +O($\emph{сложность подсчета 
% semi-local}$)=O($\emph{сложность подсчета 
% semi-local}$)$, так как $\log \log |t| \leq |p|$ для достаточно больших значений $|t|$. 
% Псевдокод алгоритма представлен на листинге~\ref{alg:patternMathing3}.

% \begin{algorithm}[h]
% \caption{Нечеткий поиск по шаблону с использованием maxRangeQuery}\label{alg:patternMathing3}
% Вход: шаблон поиска $p$, текст $t$, пороговое значение похожести $h$\\
% Выход: множество непересекающихся повторов шаблона $p$\\
% Комментарии: в реализации $h$ высчитывается исходя из схемы оценки и процента похожести, выраженного через число из отрезка $[0,1]$\\
% Псевдокод:
% \begin{algorithmic}[1]
% \State $S = SolveSemiLocalSA(p,t)$
% \State $W = BuildStructForRangeQuery(S)$
% \State $IntervalsToSearch = \emptyset $
% \State$IntervalsToSearch.add((0,|t|))$
% \State $result = \emptyset$
% \While{$IntervalsToSearch.isNotEmpty()$}
%     \State $(i,j) = IntervalsToSearch.pop()$
%     \State $score,i^{'},j^{'} = W.query(i,j)$
%     \If{$score \geq h $} 
%     \State $result.add(( i^{'},j^{'},score ))$
%     \State $IntervalsToSearch.add(i,i^{'})$        \State $IntervalsToSearch.add(j^{'},j)$
%     \EndIf
% \EndWhile
% \State $return$ $result$

% \end{algorithmic}
% \end{algorithm}


% Для апробации применимости \emph{semi-local} было решено реализовать алгоритм~\ref{alg:patternMathing2} т.к
% для~\ref{alg:patternMathing1} была произведена апробация в статье~\cite{luciv2019interactive}, а~\ref{alg:patternMathing3} на данный момент не имеет доказанных теоретических свойств и требует использования сложной структуры данных из~\cite{gawrychowski2020submatrix}.

% Для задачи поиска по образцу постпроцессинг не нужен.

\subsection{Алгоритмы для решения задачи поиска групп повторов}\label{grouppa}
В данной главе описаны алгоритмы решения задачи поиска групп повторов на основе использования \emph{библиотеки алгоритмов} и применения графовых алгоритмов.

Согласно определенной в секции~\ref{Model} модели, для решения задачи \emph{поиска групп повторов}  необходимо
задать функцию похожести $g$ и выбрать предикат $\gamma$.
Заметим, что для рассматриваемого случая, текстовыми фрагментами, в которых ищутся повторы, являются цельные \emph{JavaDoc}-комментарии.
Соответственно, в данной работе в отношении поиска групп повторов \emph{повторами} будут служить семантически замкнутые куски текста, как и в~\cite{soto2015similarity}\footnote{В~\cite{soto2015similarity} это были топики текста в \emph{Dita} документации.}, т.е \emph{JavaDoc} комментарии.

Соответственно, весь набор комментариев образует граф.
Он может быть как ориентированным, так и неориентированным.
Это зависит  от того, является ли $g$ симметричной по отношению к своим аргументам.
Таким образом, в полученном графе можно выделить группы повторов согласно предикату $\gamma$.
На~\ref{alg:groupDuplicate} представлен псевдокод алгоритма.
Отметим, что асимптотика алгоритма выражается, как $\max (O(|t|^2*g), O(s))$.

Функция $g$ может быть определена через локальное, полулокальное и глобальное выравнивание, соответственно.
В данной работе в качестве $g$ выбраны следующие алгоритмы из \emph{библиотеки алгоритмов}:
\begin{itemize}
    \item \emph{BoundedLengthSmithWaterman}~--- локальное выравнивание.
    % , симметричная функция.
    \item \emph{Semi-local sa}~--- полулокальное выравнивание.
    % не симметричная функция.
    % \item \emph{ThrehsoldAMatch} --- поиск по шаблону. 
\end{itemize}

\begin{algorithm}[t!]
\caption{Алгоритм поиска групп повторов для JavaDoc-комментариев}\label{alg:groupDuplicate}
Вход: набор комментариев $t_{i}$, функция $g$, которая меряет похожесть между двумя комментариями, функция $s$, которая согласно выбранному предикату $\gamma$ строит группы, пороговое значение похожести $h$\\
Выход: группы непересекающихся повторов\\
Псевдокод:
\begin{algorithmic}[1]
\State $graph = Graph(vertices=t)$
\For{$t_{i} \in t $}
\For{$t_{j} \in t,t_{i} \neq t_{j} $}
\If{$g(t_{i},t_{j})\geq h $}
\State $addEdge(t_{i},t_{j},g(t_{i},t_{j}))$
\EndIf
\If{$g(t_{j},t_{i}) \geq h$}
\State $addEdge(t_{j},t_{i},g(t_{j},t_{i}))$
\EndIf
\EndFor
\EndFor
\State $groups = s(graph)$
\State $return$ $groups$
\end{algorithmic}
\end{algorithm}

% На~\ref{1,2,3} представлены алгоритмы, определяющие функцию $s$

Следующие эвристические соображения помогают определить функции $s$, которые подходят для нахождения групп.

Во-первых, в силу того, что мы рассматриваем граф, естественным образом задача сводится к кластеризации графа~--- выделению компонент (сильной) связности.

Во-вторых, ориентированное ребро $a \xrightarrow{g(a,b)} b$ в графе можно естественным образом интерпретировать так: часть текста из $b$ была скопирована в фрагмент $a$ или текст $b$ был скопирован, и в новом фрагменте произведена модификация этой копии и получено $a$.
При существовании обратного ребра будем считать, что при условии $g(a,b)\geq g(b,a)$, $a$ является потомком $b$ (помним, что в общем случае $g(a,b)\neq g(b,a)$ и наоборот.

В-третьих, очень часто бывает, что повторы практически не отличаются друг от друга или же в точности совпадают друг с другом.
Такие повторы хочется различать от обычных.
Если рассматривать граф, такое состояние для части вершины выражается через термин \emph{клика}\footnote{Полный граф на заданных вершинах.} и относится к задаче поиска клики.
Соответственно, новый граф, в котором присутствуют клики, строится из исходного обновлением весов тех ребер, которые входят в клики или находятся внутри клик.


В-четвертых, ассоциированный с группой ориентированный граф должен быть деревом.
Эта эвристика основана на том, что вершина не может быть потомком сама себе (наличие циклов) и не может иметь двух одинаковых потомков (проблема множественного наследования).
Соответственно, граф является деревом.  

Исходя из описанных выше эвристик, были разработаны алгоритмы~\ref{alg:cluster1},~\ref{alg:clusterMcl}.
Также применен алгоритм из статьи~\cite{tofigh2009optimum}.

В~\ref{alg:cluster1} используется идея иерархической кластеризации с тем изменением, что добавляется новый вид вершины, который олицетворяет клики.
Как известно, поиск клики~--- это \emph{NP}-полная задача.
Поэтому в данном алгоритме произведена аппроксимация поиска клик:
листовая вершина принадлежит кластерному узлу, если её  расстояние до клики больше заданного порога похожести для клик.
% \red{Для подсчета расстояний будет использоваться \emph{минимальное расстояние между вершинами}.} 
% Существует разные варианты подсчета расстояний, о них подробно  будет описано в главе TODOапробации.
В ходе алгоритма в цикле \emph{while} происходит нахождение двух ближайших вершин согласно выбранной метрике, их объединение согласно правилам и пересчет матрицы расстояний, которая отвечает уже новому графу.
В общем случае\footnote{Некоторые метрики позволяют считать асимптотически быстрее.} пересчет матрицы требует $O(n^2)$ времени, где $n$~--- количество вершин.
В худшем случае  цикл \emph{while} будет исполняться $O(n)$ раз,
тогда асимптотика алгоритма составит $O(n^3)$.
% песос пример нужен лучше напиши епта

% иерархичпская кластеризация
\begin{algorithm}[t!]
\caption{Алгоритм выделения групп на основе Иерархической кластеризации}\label{alg:cluster1}
Вход: граф $G$ с матрицей расстояний, функция  $f$, которая считает дистанцию между вершинами, пороговое значение похожести $h_{clique}$, при котором вершины образуют очередной уровень в иерархии, $h_{group}$~--- пороговое значение похожести\\
Выход: иерархические группы повторов \\
Псевдокод:
\begin{algorithmic}[1]
\State $roots = G.vertices()$
\While{$roots.isNotEmpty()$}
\State $(from, to,score) = closestVertices(root)$
\State $newVertex = switch \{$
\State $score\geq h_{clique} , from,to \in Leaf \rightarrow Clique(from,to) $
\State $score\geq h_{clique} , to \in Clique,from \in Leaf \rightarrow to.add(from);to $
\State $score\geq h_{clique} , from,to \in Clique \rightarrow from.addAll(to);from$
\State $score\geq h_{group}, \rightarrow ClusterNode(from,to) $
\State $else \rightarrow break$ 
\State $\}$
\State $G.recalcualateDistance()$
\State $roots.remove(from)$
\State $roots.remove(to)$
\State $roots.add(newVertex)$
\EndWhile
\State $return$ $roots$
\end{algorithmic}
\end{algorithm}

В алгоритме~\ref{alg:clusterMcl} использована идея кластеризации на основе марковских моделей~\cite{dongen2000cluster} и дальнейшего построения минимальных остовных деревьев внутри каждого кластера.
 Асимптотическая сложность первого шага реализации в данной работе $O(n^3)$ в худшем случае.
 Нахождение минимального остовного дерева реализовано с помощью алгоритма Крускала с использованием системы непересекающихся множеств. Сложность второго шаге $O(n^2 \times \log n)$.
 Соответственно, общая сложность $O(n^3)$.

% mcl clustering
\begin{algorithm}[t!]
\caption{Алгоритм выделения групп на основе Марковских моделей}\label{alg:clusterMcl}
Вход: граф $G$ с матрицей расстояний\\
Выход: группы повторов с структурой группы в виде дерева\\
Псевдокод:
\begin{algorithmic}[1]
\State $trees = \emptyset$
\State $ clusters = mclClustering(G)$
\For{$cluster \in clusters$}
\State $tree =  BuildMaximumSpanningTree()$
\State $trees.add(tree)$
\EndFor
\State
\State $return$ $trees$
\end{algorithmic}
\end{algorithm}


Алгоритм~\cite{tofigh2009optimum}  решает задачу построения такого ориентированного подграфа $G_{branch}$ из исходного $G$, что:
\begin{itemize}
    \item В нем нет циклов
    \item Ни в какую вершину не входит больше одного ребра
\end{itemize}
Причем среди всех таких подграфов он оптимален:
\begin{equation}
\sum_{w \in G_{branch}} w \geq \sum_{w^{'} \in G_{branch^{'}}} w^{'}
% \forall G_{branch^{'}} 
\end{equation}
Это соотносится с последней эвристикой о том, что граф должен быть деревом.
Алгоритм из~\cite{tofigh2009optimum} обладает асимптотической сложностью $O(n^2)$.

% вероятностная кластеризация
% разбить компоненты сильной связности-> построить ориентированное дерево
%  

\vspace{10 mm}
Результаты применимости описанных алгоритмов из  данной главы к поиску повторов в документации ПО представлены в разделе~\ref{appob}.

\section{Апробация и анализ результатов}\label{appob}
В данной главе представлены результаты апробации алгоритмов из \emph{библиотеки алгоритмов полулокальных задач}.
Также дана оценка применимости решений полулокальных задач \emph{semi-local lcs и sa} к задаче поиска групп повторов в \emph{JavaDoc}-комментариях.


\subsection{Тестовый стенд}

Для проведения экспериментов использовалась
машина с процессором \emph{Intel-Core i5} и оперативной памятью размером \emph{16GB}.
Операционная система \emph{Ubuntu 18.04 Bionic}.
На каждый запуск \emph{jar}-файла выделялось $10GB$ памяти.

\subsection{Экспериментальная проверка асимптотики}

В данной секции описаны экспериментальные результаты запусков части алгоритмов из реализованной \emph{библиотеки алгоритмов} (см. главу~\ref{librarySection})  и дана их интерпретация.

На Рис.~\ref{fig:speedlcs} представлен результат запусков
обычного \emph{prefix lcs}, \emph{prefix lcs} с хранением результатов с помощью одной строки и полулокального \emph{lcs} (\emph{semi-local lcs reducing}).
Исходя из результатов, можно сделать вывод, что скорость вычисления \emph{semi-local lcs} сопоставима с вычислением обычного \emph{lcs}.

\begin{figure}[t!]
\centering
    \includegraphics[width=0.8\columnwidth]{Mishin/figures/semiLocalvsPrefixLCS.png}
    \caption{Результат запусков различных версий подсчета \emph{lcs} }\label{fig:speedlcs}
\end{figure}

\begin{figure}[t!]
\centering
    \includegraphics[width=0.8\columnwidth]{Mishin/figures/semilocalReducignVssemiLocalRecursive.png}
    \caption{Результат запусков алгоритма на основе распутывания кос и рекурсивного умножения кос для решения задачи \emph{semi-local lcs} }\label{fig:speedlcs2}
\end{figure}

На Рис.~\ref{fig:speedlcs2} представлено сравнение двух реализаций подсчета \emph{semi-local lcs}: через распутывание кос (\emph{reducing}) и  умножение кос (\emph{recursive}).
График свидетельствует о том, что сложная  рекурсивная структура алгоритма через быстрое умножение кос делает его неприменимым на практике  для строк  большой длины. Несмотря на это, такая структура алгоритма позволяет избавиться от квадратичной зависимости от параметра $v$ при решении задачи \emph{semi-local sa} (см. Рис.~\ref{fig:vParam}).
Соответственно, если реализовать итеративную версию рекурсивного алгоритма, то должно стать быстрее.
Данное замечание также справедливо для рекурсивной версии алгоритма умножения липких кос, который непосредственно используется внутри рекурсивного алгоритма.

\begin{figure}[t!]
\centering
    \includegraphics[width=0.8\columnwidth]{Mishin/figures/vDependenceImplicitSemiLocalSARecursie.png}
    \caption{Линейная зависимость параметра рекурсивного алгоритма \emph{semi-local sa} на основе умножения липких кос }\label{fig:vParam}
\end{figure}

На Рис.~\ref{fig:speedWindow3} представлены результаты запусков двух версий алгоритмов для решения задачи \emph{Window-Substring}: через предподсчет кос (\emph{implicit 350}) и наивный (\emph{naive 350})\footnote{Наивный алгоритм заключается в вычислении \emph{semi-local lcs} для каждого окна $(m \times n \times w)$, где $w$~--- размер окна, $m,n$~--- размеры строк.
}.

График  показывает, что алгоритм для решения задачи \emph{Window-Substring} через предподсчет кос действительно не зависит от размера окна и быстрее наивной версии.
Несмотря на это, в силу рекурсивной структуры  алгоритма решения, он не применим к большим данным.

\begin{figure}[t!]
\centering
    \includegraphics[width=0.8\columnwidth]{Mishin/figures/windowNaiveImpl.png}
    \caption{Независимость от размера окна }\label{fig:speedWindow3}
\end{figure}

%  \linebreak[2]

Таким образом, можно сделать вывод, что  при работе с большими данными может быть эффективно применен алгоритм решения задач \emph{semi-local} через распутывание кос. 
А алгоритмы, обладающие сложной рекурсивной структурой, могут быть применены при совершении ряда оптимизаций. Например, избавления от рекурсии.

%\subsection{Поиск по шаблону}
%В данной секции описаны результаты запусков различных версий алгоритмов решения \emph{задачи поиска по шаблону}. Также произведен их анализ.

%На Рис.~\ref{ssss}  представлены результаты временных замеров для  различных версий алгоритмов, решающих задачу поиска по шаблону.
%В частности, алгоритм из статьи~\cite{luciv2019interactive} (\emph{duplicate search}), его улучшенная версия, описанная в разделе~\ref{fics} (\emph{duplicate search via semi-local}), алгоритм из \emph{библиотеки алгоритмов} (\emph{ThresholdAMatch}) и алгоритм~\ref{alg:patternMathing2} с учетом замечания (см. псевдокод~\ref{alg:patternMathing2}).

%Рассматривались два сценария: меленький размер алфавита (большая частота повторов) и большой размер алфавита (маленькая частота повторов).
%В обоих случая размер текста был фиксирован и равен \emph{10000} слов.

% \begin{figure}[h]
%     \centering
%     \begin{subfigure}[b]{0.45\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{Mishin/figures/smallAlphabet.png} \caption{Сценарий с малым размером\\ алфавита}
%     \label{fig:subim1}
%     \end{subfigure}%
%     % \hfill
%     \begin{subfigure}[b]{0.45\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{figures/largeAlphabet.png}
%     \caption{Сценарий с большим размером\\ алфавита}
%     \label{fig:subim2}
%     \end{subfigure}
% \caption{Сравнение скорости различных алгоритмов решения задачи \emph{поиска по шаблону}}\label{ssss}
% \end{figure}

% График, во-первых, показывает, что алгоритм решения \emph{semi-local} может быть эффективно применен к \emph{задаче поиска по образцу}, а во-вторых, что улучшенная версия алгоритма из~\cite{luciv2019interactive} показывает лучшие результаты не только в теории, но и на практике.

\subsection{Поиск групп повторов}
В данной секции представлен анализ результатов запуска алгоритмов, решающих  \emph{задачу поиска групп повторов} для \emph{JavaDoc}-документации.
Анализ производился в рамках реализованного приложения (см. главу~\ref{searchPO}).
Использовались следующие фильтры: токенизация, лемматизация, удаление стоп-слов.
Повторы искались среди \emph{JavaDoc}-комментариев, относящихся к описанию методов, классов, интерфейсов.

Проекты, содержащие \emph{JavaDoc}-документацию, были выбраны на основе статей из главы~\ref{duplicateReport}.
Для нахождения групп использовался алгоритм~\ref{alg:groupDuplicate}.
В качестве функции $g$ были выбраны алгоритмы из \emph{библиотеки алгоритмов}, решающие задачи \emph{bounded-length Smith-Waterman} и \emph{semi-local sa}.
В качестве $s$ использовались алгоритм~\ref{alg:clusterMcl} и алгоритм из~\cite{tofigh2009optimum}.
Результаты представлены в таблице~\ref{table}.


\begin{figure}[t!]

\begin{center}
 \begin{tabular}{ | p{2cm} | p{1.5cm} | p{1.5cm} | p{1.5cm} | p{1.5cm} |} 
 \hline
 \thead{Название \\ проекта} & \thead{Кол-во\\  комм.} & \thead{Кол-во\\повторов} & \thead{Кол-во\\ групп} & \thead{Время \\исп. (сек)} \\
 \hline
  \makecell{slf4j} & \makecell{188} & \makecell{157} & \makecell{25} & \makecell{8} \\
  \hline
  \makecell{apache\\ commons io} & \makecell{1284} & \makecell{1180} & \makecell{92} & \makecell{569} \\
  \hline
  \makecell{apache\\ commons\\ collection} & \makecell{610} & \makecell{495} &\makecell{50} & \makecell{408} \\
  \hline
  \makecell{gson} & \makecell{498} & \makecell{356} & \makecell{81} & \makecell{96} \\
  \hline \makecell{junit} & \makecell{680} & \makecell{539} & \makecell{87} & \makecell{163} \\
  \hline \makecell{mockito} & \makecell{2979} & \makecell{2812} & \makecell{164} & \makecell{2012}\\
  \hline \makecell{guava} & \makecell{4340} & \makecell{3662} & \makecell{418} & \makecell{8505} \\
  \hline
\end{tabular}
\end{center}
\caption{Результат работы приложения}\label{table}
\end{figure}

Пример группы одного из проектов представлен на Рис.~\ref{fig:groupViz}.
Анализ проектов с помощью приложения показал следующее.

Во-первых, построение полного графа похожести~--- очень долгая операция.
Необходима предварительная фильтрация, чтобы сократить количество ребер в графе. 

Во-вторых, анализ найденных  групп показал, что они преимущественно состоят из одинаковых фрагментов (одинаковые методы, схожая функциональность) с незначительными изменениями (в графе это клики).
Сложная структура дерева (без учета клик) практически не присутствует.

В-третьих, графовые алгоритмы можно применять в задаче \emph{поиска групп повторов}.

В-четвертых, алгоритмы на основе решения задач \emph{semi-local} также могут быть успешно применены к задаче \emph{поиска групп повторов}.

Наконец, количество повторов в \emph{JavaDoc}-документации существенно, что подтверждает результаты из статей (см. главу~\ref{duplicateReport}).

% У заключения нет номера главы
\section*{Заключение}

В данной работе  исследованы существующие теоретические алгоритмы решения задач полулокального поиска наибольшей общей подпоследовательности и  выравнивания строк и реализованы в виде \emph{библиотеки алгоритмов} на языке \emph{Kotlin}.

Также были разработаны алгоритмы решения задач поиска нечетких повторов в тексте и поиска всех групп повторов.
Решения  этих задач основаны прежде всего на адаптации алгоритмов из созданной библиотеки, а так же применении  графовых эвристик и алгоритмов кластеризации в случае с поиском групп повторов. 

Для оценки практической применимости полученных решений было разработано приложение для поиска повторов  в \emph{JavaDoc} документации и проведена апробация на \emph{open source} проектах. Также было проведено экспериментальное исследование реализованных алгоритмов
решения задачи полулокального поиска наибольшей общей подпоследовательности и  выравнивания строк в контексте их применения к задачам с большим размером строк.
Результаты эксперимента показали, что часть алгоритмов имеет хорошую масштабируемость и применима к \emph{большим данным}, в то время как другие~--- не применимы в текущем виде (алгоритм \emph{муравья}). 

В итоге, можно с уверенностью сказать, что полученные в ходе работы результаты являются доказательством применимости алгоритмов решения полулокальных задач к поиску повторов в документации.

\input{Mishin/bibliography.tex}



